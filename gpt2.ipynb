{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c6d259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515e7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword1 = \"è¡Œç‚º\"\n",
    "keyword2 = \"ç¿’æ…£\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda977b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰¾åˆ° 3 æ®µè³‡æ–™\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dataset = []\n",
    "with open(r\"C:\\Users\\user\\OneDrive\\æ¡Œé¢\\project\\NLæœŸä¸­å°ˆæ¡ˆ\\keyword.jl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line.strip())\n",
    "        title = item.get(\"title\", \"\")\n",
    "        content = item.get(\"content\", \"\")\n",
    "        text = title + \"\\n\" + content\n",
    "        if keyword1 in text or keyword2 in text:\n",
    "            dataset.append(text)\n",
    "\n",
    "prompt_texts = [d[:80] for d in dataset[:3]]  # å–å‰ä¸‰ç­†ï¼Œæœ€å¤š 80 å­—\n",
    "print(f\"âœ… æ‰¾åˆ° {len(prompt_texts)} æ®µè³‡æ–™\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21213d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50304, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"IDEA-CCNL/Wenzhong-GPT2-110M\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aed097f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“° ç¬¬ 1 æ®µç”Ÿæˆï¼š\n",
      "å½±ï¼å°74ç·šå‡ºç¾å¤©å¤–é£›ç‰© 27æ”¯éµæ¢å™´é£›ç ¸åˆ°å°å‘2è»Š\n",
      "\n",
      "ä»Šå¤©ä¸­åˆ11æ™‚44åˆ†è¨±ï¼Œ26æ­²çš„è¨±ç”·é§•é§›è‡ªå°è²¨è»Šï¼Œè¡Œé§›åœ¨æ½­å­å€å°74ç·šå¿«é€Ÿé“è·¯æ±å‘20.5å…¬é‡Œè™•ï¼Œå› è»Šæœ‰è­¦é¥­å ‚èŒ¶å¹å¾€åä¸€æ”¯é“ï¼Œæ”¯é…é“æŠ±æ§åœ¨å¸æ‹‰è‚šä¸Šæ‰€æŠ±æ§ï¼Œç„¶åæ‹‰è‚šä»åæ”¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“° ç¬¬ 2 æ®µç”Ÿæˆï¼š\n",
      "å—éŸ“å¤§é¸é¨·å‹•ä¸æ–· 690äººæ¯€æç«¶é¸æµ·å ±é­æª¢èˆ‰\n",
      "å—éŸ“6æœˆ3æ—¥å°‡èˆ‰è¡Œç¬¬21å±†ç¸½çµ±å¤§é¸ï¼Œå„é»¨å€™é¸äººå¦‚ç«å¦‚è¼é€²è¡Œç«¶é¸æ´»å‹•çš„åŒæ™‚ï¼Œä»¥é•æ³•è¡Œç‚ºå¹²æ“¾ç«¶é¸æ´»å‹•çš„æ¡ˆä»¶å±¤å‡ºä¸çª®ï¼Œå…‰ç»ªå¹´é—´å°‡èˆ‰æ¯äº‹çš„å‡æ´»èˆ¹ç˜¥å† ç»£ç‰ç’ºç®¬ç«¶é¸æ´»å‹•ç½ªè¯æ— å—ï¼Œåªèƒ½é€²ä¹¦è§£æ”¾èˆ¹\n",
      "\n",
      "ğŸ“° ç¬¬ 3 æ®µç”Ÿæˆï¼š\n",
      "6äº‹æ¥­åˆèˆ¹é€²å£ç‰ç±³...è¯åˆè¡Œç‚ºå±•å»¶ å…¬å¹³æœƒæœ‰æ¢ä»¶é€šé\n",
      "å°ç£æ¥­è€…åˆèˆ¹é€²å£è¡Œä¹‹æœ‰å¹´ï¼Œèªç‚ºï¼Œæ­¤äº‹é›–å±¬è¯åˆè¡Œç‚ºï¼Œä½†å°ç£å¹¾ä¹å…¨ä»°è³´é€²å£ï¼Œæ­¤èˆ‰æœ‰ç›Šæ•´é«”ç¶“æ¿Ÿåˆ©ç›ŠåŠå…¬å…±åˆ©ç›Šï¼Œæ¥­è€…å®œå°‘èµ·å»¶æ¯”ã€‚å±•å»¶å…¬å¹³æœƒæœ‰è«èƒ½ä¸‹æµ‡ï¼Œæ·†è–„æŠ¼æºƒæŠšæ’‘ï¼Œä»¿ä½›ç¾¤ä¼—ä¸‹ç‚®å°±\n"
     ]
    }
   ],
   "source": [
    "for i, base in enumerate(prompt_texts):\n",
    "    input_ids = tokenizer.encode(base, return_tensors=\"pt\")\n",
    "\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=80,     # â† ç”Ÿæˆæœ€å¤š 80 å€‹æ–° token\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.9\n",
    "    )\n",
    "\n",
    "    result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(f\"\\nğŸ“° ç¬¬ {i+1} æ®µç”Ÿæˆï¼š\\n{result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04779aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
